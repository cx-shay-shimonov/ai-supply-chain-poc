{
  "query": "usages of gpt-5, gpt-5-latest, gpt-5-2025-11-04, gpt-5-pro, gpt-5-mini, gpt-5-nano, o4-mini, o3-high, gpt-4.1-mini, gpt-4o, gpt-oss-120b, claude-opus-4-5-latest, claude-opus-4-5-20251101, claude-sonnet-4-5-latest, claude-sonnet-4-5-20250929, claude-haiku-4-5, claude-3-5-haiku-latest, claude-code-2-1, gemini-3-pro, gemini-3-flash, gemini-2.5-pro, gemini-2.5-flash, gemini-2.5-flash-lite, gemini-live-2.5-flash-native-audio, deepseek-v4, deepseek-v3.2, deepseek-reasoner, deepseek-chat, llama-3.3-70b-instruct, llama-3.1-405b-instruct, llama-4-preview-70b, mistral-large-2511, mistral-nemo-latest, pixtral-large-latest, codestral-latest, grok-4-fast-reasoning, grok-code-fast-1, glm-4.7-thinking, qwen3-72b-instruct, mimo-v2-flash",
  "repository": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui",
  "results": [
    {
      "rank": 1,
      "score": 0.3904736042022705,
      "certainty": "medium",
      "certainty_percent": 55.13,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 590,
      "code": "function isRTL(text) {\n    const rtlPattern = /[\\u0590-\\u05FF\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF]/;\n    return rtlPattern.test(text);\n}"
    },
    {
      "rank": 2,
      "score": 0.35784733295440674,
      "certainty": "medium",
      "certainty_percent": 50.99,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/server.js",
      "line": 70,
      "code": "app.post('/api/generate-background', async (req, res) => {\n    try {\n        const { conversationContext } = req.body;\n\n        if (!conversationContext) {\n            return res.status(400).json({ error: 'Conversation context is required' });\n        }\n\n\n        const model = `${modelName}-${modelVersion}`;\n        // First, ask GPT to create an image prompt based on the conversation\n        const promptResponse = await openai.chat.completions.create({\n            // model: 'gpt-4o-mini',\n            model: model,\n            messages: [\n                {\n                    role: 'system',\n                    content: `You are an expert at creating DALL-E image prompts. Based on the conversation context provided, create a single, visually stunning image prompt that captures the mood and theme of the discussion. The image should be VIVID, COLORFUL, and STRIKING - with rich, saturated colors and dramatic visual impact. Output ONLY the image prompt, nothing else. Make it artistic, bold, and memorable. Add \"vivid colors, dramatic lighting, high contrast, vibrant, cinematic, artistic, visually striking\" to ensure maximum visual impact.`\n                },\n                {\n                    role: 'user',\n                    content: `Create an image prompt based on this conversation:\\n\\n${conversationContext}`\n                }\n            ],\n            max_tokens: 150\n        });\n\n        const imagePrompt = promptResponse.choices[0]?.message?.content?.trim();\n        console.log('üé® Generated image prompt:', imagePrompt);\n\n        // Generate image with DALL-E\n        const imageResponse = await openai.images.generate({\n            model: 'dall-e-3',\n            prompt: imagePrompt,\n            n: 1,\n            size: '1792x1024',\n            quality: 'standard',\n            style: 'vivid'\n        });\n\n        const imageUrl = imageResponse.data[0]?.url;\n        console.log('üñºÔ∏è Generated image URL:', imageUrl);\n\n        res.json({ \n            success: true, \n            imageUrl,\n            prompt: imagePrompt \n        });\n\n    } catch (error) {\n        console.error('Image generation error:', error);\n        res.status(500).json({ \n            error: 'Failed to generate image',\n            details: error.message \n        });\n    }\n});"
    },
    {
      "rank": 3,
      "score": 0.34395724534988403,
      "certainty": "low",
      "certainty_percent": 48.23,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 596,
      "code": "function getTextDirection(text) {\n    return isRTL(text) ? 'rtl' : 'ltr';\n}"
    },
    {
      "rank": 4,
      "score": 0.3335476517677307,
      "certainty": "low",
      "certainty_percent": 46.92,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 102,
      "code": "function autoResizeTextarea() {\n    messageInput.style.height = 'auto';\n    messageInput.style.height = Math.min(messageInput.scrollHeight, 200) + 'px';\n}"
    },
    {
      "rank": 5,
      "score": 0.303236722946167,
      "certainty": "low",
      "certainty_percent": 43.08,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 315,
      "code": "function createAssistantMessage() {\n    const message = document.createElement('div');\n    message.className = 'message assistant';\n\n    message.innerHTML = `\n        <div class=\"message-avatar\">\n            <svg viewBox=\"0 0 41 41\" fill=\"none\" width=\"20\" height=\"20\">\n                <path d=\"M37.5324 16.8707C37.9808 15.5241 38.1363 14.0974 37.9886 12.6859C37.8409 11.2744 37.3934 9.91076 36.676 8.68622C35.6126 6.83404 33.9882 5.3676 32.0373 4.4985C30.0864 3.62941 27.9098 3.40259 25.8215 3.85078C24.8796 2.7893 23.7219 1.94125 22.4257 1.36341C21.1295 0.785575 19.7249 0.491269 18.3058 0.500528C16.1708 0.495061 14.0893 1.16803 12.3614 2.42214C10.6335 3.67624 9.34853 5.44666 8.6917 7.47815C7.30085 7.76286 5.98686 8.3414 4.8377 9.17505C3.68854 10.0087 2.73073 11.0782 2.02839 12.312C0.956464 14.1591 0.498905 16.2988 0.721698 18.4228C0.944492 20.5467 1.83612 22.5449 3.268 24.1293C2.81966 25.4759 2.66413 26.9026 2.81182 28.3141C2.95951 29.7256 3.40701 31.0892 4.12437 32.3138C5.18791 34.1659 6.8123 35.6322 8.76321 36.5013C10.7141 37.3704 12.8907 37.5973 14.9789 37.1492C15.9208 38.2107 17.0786 39.0587 18.3747 39.6366C19.6709 40.2144 21.0755 40.5087 22.4946 40.4995C24.6307 40.5054 26.7133 39.8321 28.4418 38.5772C30.1704 37.3223 31.4556 35.5506 32.1119 33.5179C33.5027 33.2332 34.8167 32.6547 35.9659 31.821C37.1151 30.9873 38.0729 29.9178 38.7752 28.684C39.8462 26.8371 40.3034 24.6979 40.0804 22.5765C39.8574 20.455 38.9659 18.459 37.5324 16.8707Z\" fill=\"currentColor\"/>\n            </svg>\n        </div>\n        <div class=\"message-content\">\n            <div class=\"message-bubble\"></div>\n        </div>\n    `;\n\n    messagesContainer.appendChild(message);\n    scrollToBottom();\n    return message;\n}"
    },
    {
      "rank": 6,
      "score": 0.2939457893371582,
      "certainty": "low",
      "certainty_percent": 41.9,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 229,
      "code": "async function getAIResponse(userMessage) {\n    isTyping = true;\n    updateSendButton();\n\n    // Add user message to conversation history\n    conversationHistory.push({\n        role: 'user',\n        content: userMessage\n    });\n\n    addTypingIndicator();\n\n    try {\n        const response = await fetch('/api/chat', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({\n                messages: [\n                    { role: 'system', content: 'You are ChatGPT, a helpful AI assistant created by OpenAI. Be helpful, harmless, and honest.' },\n                    ...conversationHistory\n                ]\n            })\n        });\n\n        if (!response.ok) {\n            throw new Error('Failed to get response');\n        }\n\n        removeTypingIndicator();\n\n        // Create assistant message element for streaming\n        const assistantMessage = createAssistantMessage();\n        const bubbleEl = assistantMessage.querySelector('.message-bubble');\n        let fullResponse = '';\n\n        // Read the stream\n        const reader = response.body.getReader();\n        const decoder = new TextDecoder();\n\n        while (true) {\n            const { done, value } = await reader.read();\n            if (done) break;\n\n            const chunk = decoder.decode(value);\n            const lines = chunk.split('\\n');\n\n            for (const line of lines) {\n                if (line.startsWith('data: ')) {\n                    const data = line.slice(6);\n                    if (data === '[DONE]') continue;\n\n                    try {\n                        const parsed = JSON.parse(data);\n                        if (parsed.content) {\n                            fullResponse += parsed.content;\n                            // Update direction based on content for RTL support\n                            bubbleEl.dir = getTextDirection(fullResponse);\n                            bubbleEl.innerHTML = formatMessage(fullResponse);\n                            scrollToBottom();\n                        }\n                    } catch (e) {\n                        // Ignore parse errors for incomplete chunks\n                    }\n                }\n            }\n        }\n\n        // Add to conversation history\n        conversationHistory.push({\n            role: 'assistant',\n            content: fullResponse\n        });\n\n    } catch (error) {\n        console.error('Error:', error);\n        removeTypingIndicator();\n        addMessage('Sorry, I encountered an error. Please try again.', 'assistant');\n    }\n\n    isTyping = false;\n    updateSendButton();\n}"
    },
    {
      "rank": 7,
      "score": 0.2932550311088562,
      "certainty": "low",
      "certainty_percent": 41.81,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/server.js",
      "line": 24,
      "code": "app.post('/api/chat', async (req, res) => {\n    try {\n        const { messages } = req.body;\n\n        if (!messages || !Array.isArray(messages)) {\n            return res.status(400).json({ error: 'Messages array is required' });\n        }\n\n        // Set headers for streaming\n        res.setHeader('Content-Type', 'text/event-stream');\n        res.setHeader('Cache-Control', 'no-cache');\n        res.setHeader('Connection', 'keep-alive');\n\n        const stream = await openai.chat.completions.create({\n            model: 'gpt-4o-mini',\n            messages: messages,\n            stream: true,\n        });\n\n        for await (const chunk of stream) {\n            const content = chunk.choices[0]?.delta?.content || '';\n            if (content) {\n                res.write(`data: ${JSON.stringify({ content })}\\n\\n`);\n            }\n        }\n\n        res.write('data: [DONE]\\n\\n');\n        res.end();\n\n    } catch (error) {\n        console.error('OpenAI API Error:', error);\n\n        // If headers haven't been sent yet, send error response\n        if (!res.headersSent) {\n            res.status(500).json({ \n                error: 'Failed to get response from AI',\n                details: error.message \n            });\n        } else {\n            res.write(`data: ${JSON.stringify({ error: error.message })}\\n\\n`);\n            res.end();\n        }\n    }\n});"
    },
    {
      "rank": 8,
      "score": 0.2793211042881012,
      "certainty": "low",
      "certainty_percent": 40.05,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 196,
      "code": "function addTypingIndicator() {\n    const indicator = document.createElement('div');\n    indicator.className = 'message assistant';\n    indicator.id = 'typingIndicator';\n\n    indicator.innerHTML = `\n        <div class=\"message-avatar\">\n            <svg viewBox=\"0 0 41 41\" fill=\"none\" width=\"20\" height=\"20\">\n                <path d=\"M37.5324 16.8707C37.9808 15.5241 38.1363 14.0974 37.9886 12.6859C37.8409 11.2744 37.3934 9.91076 36.676 8.68622C35.6126 6.83404 33.9882 5.3676 32.0373 4.4985C30.0864 3.62941 27.9098 3.40259 25.8215 3.85078C24.8796 2.7893 23.7219 1.94125 22.4257 1.36341C21.1295 0.785575 19.7249 0.491269 18.3058 0.500528C16.1708 0.495061 14.0893 1.16803 12.3614 2.42214C10.6335 3.67624 9.34853 5.44666 8.6917 7.47815C7.30085 7.76286 5.98686 8.3414 4.8377 9.17505C3.68854 10.0087 2.73073 11.0782 2.02839 12.312C0.956464 14.1591 0.498905 16.2988 0.721698 18.4228C0.944492 20.5467 1.83612 22.5449 3.268 24.1293C2.81966 25.4759 2.66413 26.9026 2.81182 28.3141C2.95951 29.7256 3.40701 31.0892 4.12437 32.3138C5.18791 34.1659 6.8123 35.6322 8.76321 36.5013C10.7141 37.3704 12.8907 37.5973 14.9789 37.1492C15.9208 38.2107 17.0786 39.0587 18.3747 39.6366C19.6709 40.2144 21.0755 40.5087 22.4946 40.4995C24.6307 40.5054 26.7133 39.8321 28.4418 38.5772C30.1704 37.3223 31.4556 35.5506 32.1119 33.5179C33.5027 33.2332 34.8167 32.6547 35.9659 31.821C37.1151 30.9873 38.0729 29.9178 38.7752 28.684C39.8462 26.8371 40.3034 24.6979 40.0804 22.5765C39.8574 20.455 38.9659 18.459 37.5765 16.8707H37.5324Z\" fill=\"currentColor\"/>\n            </svg>\n        </div>\n        <div class=\"message-content\">\n            <div class=\"typing-indicator\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n    `;\n\n    messagesContainer.appendChild(indicator);\n    scrollToBottom();\n}"
    },
    {
      "rank": 9,
      "score": 0.2725291848182678,
      "certainty": "low",
      "certainty_percent": 39.19,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 160,
      "code": "function sendSuggestion(card) {\n    const title = card.querySelector('span').textContent;\n    const subtitle = card.querySelector('p').textContent;\n    messageInput.value = `${title} ${subtitle}`;\n    sendMessage();\n}"
    },
    {
      "rank": 10,
      "score": 0.26406896114349365,
      "certainty": "low",
      "certainty_percent": 38.12,
      "file": "/Users/shayshimonov/Projects/ai-supply-chain/sem-poc/projects-samples/ai-ui/script.js",
      "line": 44,
      "code": "function applyTheme(isDark) {\n    if (isDark) {\n        document.documentElement.setAttribute('data-theme', 'dark');\n    } else {\n        document.documentElement.removeAttribute('data-theme');\n    }\n    localStorage.setItem('theme', isDark ? 'dark' : 'light');\n}"
    }
  ]
}
